# Configuration for Topology-Aware nnU-Net Training - v9_progressive
# Strategy: Progressive loss scheduling to break plateau
# Phase 1 (Epochs 0-30): Pure Dice - establish spatial learning baseline
# Phase 2 (Epochs 31-60): Add focal loss gradually - hard negative mining
# Phase 3 (Epochs 61-300): Full loss ensemble - balanced optimization

# Model architecture
in_channels: 1
out_channels: 1
initial_filters: 32
depth: 4

# Training parameters
batch_size: 8              # Larger batches for stable gradients
num_epochs: 50             # Reduced for faster iteration (SWA at epoch 30)
learning_rate: 0.0005      # Moderate (2x v8 baseline for exploration)
weight_decay: 0.0001       # Conservative regularization
warmup_epochs: 2           # Minimal warmup

# Data parameters
patch_size: [128, 128, 128]
num_workers: 4

# Cross-validation
n_folds: 5

# Progressive Loss Schedule
# Loss weights transition over training to prevent conflicting objectives
progressive_loss_schedule: true
progressive_phases:
  # Phase 1: Pure Dice (Epochs 0-30)
  # Goal: Establish solid spatial structure learning without confusion
  # Why: Dice measures overlap quality directly (primary goal)
  - phase: 1
    epoch_start: 0
    epoch_end: 30
    loss_weights:
      dice_weight: 1.0       # DOMINANT: Focus on overlap
      focal_weight: 0.0      # OFF: No hard negative mining yet
      variance_weight: 0.0   # OFF: Let model be confident
      boundary_weight: 0.0   # OFF: Simple objective
      cldice_weight: 0.0
      connectivity_weight: 0.0
    target: "Break initial plateau with clear signal"

  # Phase 2: Dice + Minimal Focal (Epochs 31-39)
  # Goal: Introduce hard negative mining VERY GRADUALLY
  # Why: After learning basic structure, add weak hard negative focus
  # UPDATED: Focal reduced to 0.05 to prevent catastrophic loss spikes
  - phase: 2
    epoch_start: 31
    epoch_end: 39
    loss_weights:
      dice_weight: 0.95      # Maintain primary objective strongly
      focal_weight: 0.05     # VERY GRADUAL: Add hard negatives (only 5% - half strength)
      variance_weight: 0.0   # OFF: Still confident
      boundary_weight: 0.0   # OFF: Not needed yet
      cldice_weight: 0.0
      connectivity_weight: 0.0
    target: "Gentle introduction of hard-negative mining"

  # Phase 3: Full Ensemble (Epochs 61-300)
  # Goal: Balanced multi-objective optimization
  # Why: Model has learned fundamentals, now balance all constraints
  # Phase 3: Balanced Ensemble (Epochs 40-50)
  # Goal: Smooth transition to full multi-objective learning
  # Why: Model has learned fundamentals, now balance all constraints
  # UPDATED: Start with gradual weights, build up focal to 0.10 (instead of 0.15)
  - phase: 3
    epoch_start: 40
    epoch_end: 50
    loss_weights:
      dice_weight: 0.85      # PRIMARY: Keep spatial overlap strong
      focal_weight: 0.10     # Secondary: Hard negatives (doubled from Phase 2)
      variance_weight: 0.03  # Tertiary: Gentle uncertainty penalty
      boundary_weight: 0.02  # Tertiary: Light surface quality
      cldice_weight: 0.0     # Disabled
      connectivity_weight: 0.0
    target: "Converge to balanced solution with stable objectives"

# Focal loss parameters
focal_gamma: 2.0
focal_alpha: 0.4

# Class weights - BALANCED
use_class_weights: false  # Let loss weights handle balance
background_weight: 1.0
foreground_weight: 1.5

# Learning rate scheduler
scheduler_type: "plateau"
scheduler_patience: 8      # More patience for phase transitions
scheduler_factor: 0.5
scheduler_threshold: 0.0005

# SWA - enabled for final convergence
swa_enabled: true
swa_start_epoch: 30        # Start at epoch 30 (halfway through training)

# Noise - minimal (only for diversity)
noise_enabled: true
noise_start_epoch: 50      # After phase 1 completes
noise_frequency: 10
noise_std: 0.001

# Early stopping - reasonable
early_stopping_patience: 40

# Adaptive interventions for plateau recovery
adaptive_interventions_enabled: true
adaptive_intervention_patience: 3        # Trigger after 3 degrading epochs
adaptive_intervention_lr_multiplier: 1.2 # Conservative: 20% LR boost per trigger
