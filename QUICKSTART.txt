â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    QUICK START: TRAIN REMAINING FOLDS                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ SIMPLEST METHOD (Recommended):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
cd /home/swatson/work/MachineLearning/kaggle/vesuvius-challenge-surface-detection/bin
./quick_train_all.sh

â±ï¸  Estimated time: ~55 hours for all 5 folds (or ~44 hours for folds 1-4)


ğŸ“Š WHAT CHANGED:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Early stopping now automatically continues to next fold
âœ… SWA starts at epoch 40 (was 50) - gets used before early stopping
âœ… Single command runs all folds
âœ… Comprehensive progress tracking and summary


ğŸ¯ KEY COMMANDS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£  Run All Folds (0-4):
    cd bin && python train.py --fold -1 --continue-on-error

2ï¸âƒ£  Run Single Fold:
    python train.py --fold 3  # Run only fold 3

3ï¸âƒ£  Monitor Progress:
    tail -f ../log/train_all_folds_*.log | grep "FOLD\|complete"

4ï¸âƒ£  Check GPU:
    watch -n 5 nvidia-smi


ğŸ“ OUTPUT FILES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Log file:       log/train_all_folds_YYYYMMDD_HHMMSS.log
Checkpoints:    bin/checkpoints/fold_0/ through fold_4/
SWA models:     bin/checkpoints/fold_N/swa_model.pth


ğŸ’¡ TIPS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Training auto-continues after early stopping - no manual intervention!
â€¢ Each fold takes ~11 hours based on fold 0
â€¢ --continue-on-error flag keeps going even if one fold fails
â€¢ Press Ctrl+Z then 'bg' to background the process if needed
â€¢ Use 'nohup ./quick_train_all.sh &' to run in background from start


ğŸ“‹ FOLD 0 RESULTS (Baseline):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Epochs: 50 (early stopped)
â€¢ Time: 10.83 hours
â€¢ Val Loss: 0.0851
â€¢ Dice Score: 0.5807
â€¢ Improvement: 60.3% loss reduction, 22.6% dice improvement


ğŸ” TROUBLESHOOTING:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Issue: "Module not found"
â†’ conda activate phi4

Issue: Out of memory
â†’ Edit config.yaml: batch_size: 1

Issue: Want to stop training
â†’ Ctrl+C (gracefully stops current epoch)

Issue: Training seems stuck
â†’ Check log file for errors
â†’ Check GPU with nvidia-smi


ğŸ“– MORE INFO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Full guide: TRAINING_FOLDS_GUIDE.md
â€¢ Change details: TRAINING_UPDATE_SUMMARY.md
â€¢ Original training notes: TRAINING_FIX.md
